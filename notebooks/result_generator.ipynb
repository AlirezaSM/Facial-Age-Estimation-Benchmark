{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def parse_log_and_format(input_text):\n",
    "#     # Regex patterns to extract numbers\n",
    "#     patterns = {\n",
    "#         \"train_error\": r\"\\[trn phase\\]\\n.*?error: ([\\d.]+)\",\n",
    "#         \"train_loss\": r\"\\[trn phase\\]\\n.*?loss: ([\\d.]+)\",\n",
    "#         \"val_error\": r\"\\[val phase\\]\\n.*?error: ([\\d.]+)\",\n",
    "#         \"val_loss\": r\"\\[val phase\\]\\n.*?loss: ([\\d.]+)\",\n",
    "#         \"best_epoch\": r\"Best Epoch: (\\d+)\",\n",
    "#         \"train_mae\": r\"\\[trn set\\]\\n.*?age \\(mae\\): ([\\d.]+)\",\n",
    "#         \"val_mae\": r\"\\[val set\\]\\n.*?age \\(mae\\): ([\\d.]+)\",\n",
    "#         \"test_mae\": r\"\\[tst set\\]\\n.*?age \\(mae\\): ([\\d.]+)\"\n",
    "#     }\n",
    "\n",
    "#     # Extract values using regex\n",
    "#     results = {}\n",
    "#     for key, pattern in patterns.items():\n",
    "#         match = re.search(pattern, input_text, re.DOTALL)\n",
    "#         results[key] = match.group(1) if match else \"-\"\n",
    "\n",
    "#     # Format the output\n",
    "#     output = (\n",
    "#         f\"{results['train_mae']}/{results['train_error']}, \"\n",
    "#         f\"-/{results['train_loss']}, \"\n",
    "#         f\"{results['val_mae']}/{results['val_error']}, \"\n",
    "#         f\"-/{results['val_loss']}, \"\n",
    "#         f\"{results['test_mae']}, \"\n",
    "#         f\"{results['best_epoch']}/49\"\n",
    "#     )\n",
    "\n",
    "#     return output\n",
    "\n",
    "# # Input text\n",
    "# log_text = \"\"\"\n",
    "# 2025-02-15 14:52:26,345 [INFO] Number of trn data 10954\n",
    "# 2025-02-15 14:52:26,345 [INFO] Number of val data 3069\n",
    "# 2025-02-15 14:52:26,737 [INFO] Epoch 49/49\n",
    "# 2025-02-15 14:52:26,738 [INFO] ----------------------------------------\n",
    "# 2025-02-15 14:52:45,733 [INFO] [trn phase]\n",
    "# 2025-02-15 14:52:45,733 [INFO] error: 1.0416 age_error:1.0416\n",
    "# 2025-02-15 14:52:45,733 [INFO] loss: 0.1545 age_loss:0.1545\n",
    "# 2025-02-15 14:52:51,753 [INFO] [val phase]\n",
    "# 2025-02-15 14:52:51,753 [INFO] error: 1.1720 age_error:1.1720\n",
    "# 2025-02-15 14:52:51,753 [INFO] loss: 0.4443 age_loss:0.4443\n",
    "# 2025-02-15 14:52:51,753 [INFO] Best Epoch: 46\n",
    "# 2025-02-15 14:52:52,248 [INFO] Checkpoint saved to facebase/results/Adience_256x256_resnet50_imagenet_noisy_dldl_v2/split0/checkpoint_49.pth\n",
    "# 2025-02-15 14:52:52,935 [INFO] Training complete in 0m 27s\n",
    "# 2025-02-15 14:52:52,935 [INFO] Best epoch: 46\n",
    "# 2025-02-15 14:53:21,847 [INFO] Model evalution:\n",
    "# 2025-02-15 14:53:21,847 [INFO] [trn set]\n",
    "# 2025-02-15 14:53:21,847 [INFO] age (mae): 0.1308\n",
    "# 2025-02-15 14:53:21,847 [INFO] [val set]\n",
    "# 2025-02-15 14:53:21,847 [INFO] age (mae): 0.1887\n",
    "# 2025-02-15 14:53:21,847 [INFO] [tst set]\n",
    "# 2025-02-15 14:53:21,847 [INFO] age (mae): 0.6852\n",
    "# \"\"\"\n",
    "\n",
    "# # Parse and format the log\n",
    "# formatted_output = parse_log_and_format(log_text)\n",
    "# print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_metrics_from_log(root_folder):\n",
    "    results = []\n",
    "    \n",
    "    for i in range(5):  # Iterate through split0 to split4\n",
    "        log_path = os.path.join(root_folder, f'split{i}', 'training.log')\n",
    "        \n",
    "        if not os.path.exists(log_path):\n",
    "            print(f\"Warning: {log_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        with open(log_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        if len(lines) < 21:\n",
    "            print(f\"Warning: {log_path} has less than 21 lines.\")\n",
    "            continue\n",
    "        \n",
    "        last_lines = lines[-21:]\n",
    "\n",
    "        # Initialize variables\n",
    "        trn_mae = val_mae = tst_mae = None\n",
    "        trn_err = val_err = None\n",
    "        trn_loss = val_loss = None\n",
    "        best_epoch = total_epochs = None\n",
    "        \n",
    "        for j, line in enumerate(last_lines):\n",
    "            # Extract MAE values for training, validation, and test sets\n",
    "            if \"[INFO] [trn set]\" in line:\n",
    "                trn_mae = float(re.search(r\"[-+]?\\d*\\.\\d+\", last_lines[j + 1]).group())\n",
    "            elif \"[INFO] [val set]\" in line:\n",
    "                val_mae = float(re.search(r\"[-+]?\\d*\\.\\d+\", last_lines[j + 1]).group())\n",
    "            elif \"[INFO] [tst set]\" in line:\n",
    "                tst_mae = float(re.search(r\"[-+]?\\d*\\.\\d+\", last_lines[j + 1]).group())\n",
    "\n",
    "            # Extract error and loss values for training phase\n",
    "            elif \"[INFO] [trn phase]\" in line:\n",
    "                # print(i, line)\n",
    "                trn_err = float(re.search(r\"error: ([\\d.]+)\", last_lines[j + 1]).group(1))\n",
    "                trn_loss = float(re.search(r\"loss: ([\\d.]+)\", last_lines[j + 2]).group(1))\n",
    "\n",
    "            # Extract error and loss values for validation phase\n",
    "            elif \"[INFO] [val phase]\" in line:\n",
    "                val_err = float(re.search(r\"error: ([\\d.]+)\", last_lines[j + 1]).group(1))\n",
    "                val_loss = float(re.search(r\"loss: ([\\d.]+)\", last_lines[j + 2]).group(1))\n",
    "\n",
    "            # Extract best epoch (correcting the issue)\n",
    "            elif \"[INFO] Best Epoch:\" in line:\n",
    "                best_epoch = int(line.split()[-1])  # Take the **last** element, ignoring timestamp\n",
    "\n",
    "            # Extract total epochs\n",
    "            elif \"[INFO] Epoch\" in line:\n",
    "                # print(i, line)\n",
    "                match = re.search(r\"Epoch (\\d+)/(\\d+)\", line)\n",
    "                if match:\n",
    "                    total_epochs = int(match.group(2))\n",
    "\n",
    "        if None in [trn_mae, val_mae, tst_mae, trn_err, val_err, trn_loss, val_loss, best_epoch, total_epochs]:\n",
    "            print(f\"Warning: Missing data in {log_path}\")\n",
    "            continue\n",
    "\n",
    "        result_line = (\n",
    "            f\"{trn_mae}/{trn_err}, -/{trn_loss}, \"\n",
    "            f\"{val_mae}/{val_err}, -/{val_loss}, \"\n",
    "            f\"{tst_mae}, {best_epoch}/{total_epochs}\"\n",
    "        )\n",
    "        results.append(result_line)\n",
    "    \n",
    "    return(\"\\n\".join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_and_calculate(input_text):\n",
    "    # Split input text into rows and then into individual numbers\n",
    "    rows = input_text.strip().split(\"\\n\")\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        # Split by tab, then further split by '/' and remove '-'\n",
    "        parsed_row = []\n",
    "        for item in row.split(\"\\t\"):\n",
    "            parts = item.split(\"/\")\n",
    "            for part in parts:\n",
    "                if part != \"-\":\n",
    "                    parsed_row.append(float(part))\n",
    "        data.append(parsed_row)\n",
    "    \n",
    "    # Convert to numpy array for easier calculations\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Calculate mean and variance for each column\n",
    "    means = np.mean(data, axis=0)\n",
    "    variances = np.sqrt(np.var(data, axis=0))\n",
    "    # Format the output with 4-digit precision\n",
    "    output = (\n",
    "        f\"{means[0]:.4f}±{variances[0]:.4f}/{means[1]:.4f}±{variances[1]:.4f}, \"\n",
    "        f\"-/{means[2]:.4f}±{variances[2]:.4f}, \"\n",
    "        f\"{means[3]:.4f}±{variances[3]:.4f}/{means[4]:.4f}±{variances[4]:.4f}, \"\n",
    "        f\"-/{means[5]:.4f}±{variances[5]:.4f}, \"\n",
    "        f\"{means[6]:.4f}±{variances[6]:.4f}, \"\n",
    "        f\"{means[7]:.4f}±{variances[7]:.4f}/{int(means[8])}\"\n",
    "    )\n",
    "    return output\n",
    "\n",
    "# # Input text\n",
    "# input_text = \"\"\"\n",
    "# 2.2147/0.1539\t-/0.3586\t3.9127/3.7393\t-/7.7739\t0.7961\t16/49\n",
    "# 2.2468/0.1155\t-/0.2987\t2.1100/2.9188\t-/6.7673\t0.6471\t14/49\n",
    "# 2.8323/0.1059\t-/0.2732\t2.7364/3.1347\t-/6.8584\t0.7042\t13/49\n",
    "# 2.3817/0.1371\t-/0.3173\t2.6194/3.6016\t-/8.6991\t0.763\t14/49\n",
    "# 2.9028/0.1866\t-/0.3942\t1.3841/2.6257\t-/7.1335\t0.7087\t14/49\n",
    "# \"\"\"\n",
    "# print(input_text)\n",
    "# # Calculate and print the result\n",
    "# result = parse_and_calculate(input_text)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0477/0.3701, -/0.0708, 0.288/0.4695, -/0.5984, 0.4202, 17/49\n",
      "0.0445/0.3915, -/0.0716, 0.3097/0.4188, -/0.6323, 0.4246, 23/49\n",
      "0.0481/0.3615, -/0.0695, 0.4087/0.5684, -/0.8321, 0.36, 16/49\n",
      "0.0582/0.3783, -/0.0687, 0.2571/0.3728, -/0.496, 0.5095, 14/49\n",
      "0.0659/0.4163, -/0.0689, 0.3069/0.5088, -/0.7122, 0.3443, 10/49\n"
     ]
    }
   ],
   "source": [
    "root_path = '../facebase/results/Adience_256x256_resnet50_imagenet_noisy_dldl_v2_clean_corrected'\n",
    "split_metrics = extract_metrics_from_log(root_path)\n",
    "print(split_metrics, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0529±0.0080/0.3835±0.0191, -/0.0699±0.0011, 0.3141±0.0509/0.4677±0.0682, -/0.6542±0.1128, 0.4117±0.0583, 16.0000±4.2426/49\n"
     ]
    }
   ],
   "source": [
    "split_metrics = split_metrics.replace(', ', '\\t')\n",
    "print(parse_and_calculate(split_metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
