{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8559/0.9139, -/0.0467, 1.3137/1.3925, -/0.6457, 0.7033, 9/49\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_log_and_format(input_text):\n",
    "    # Regex patterns to extract numbers\n",
    "    patterns = {\n",
    "        \"train_error\": r\"\\[trn phase\\]\\n.*?error: ([\\d.]+)\",\n",
    "        \"train_loss\": r\"\\[trn phase\\]\\n.*?loss: ([\\d.]+)\",\n",
    "        \"val_error\": r\"\\[val phase\\]\\n.*?error: ([\\d.]+)\",\n",
    "        \"val_loss\": r\"\\[val phase\\]\\n.*?loss: ([\\d.]+)\",\n",
    "        \"best_epoch\": r\"Best Epoch: (\\d+)\",\n",
    "        \"train_mae\": r\"\\[trn set\\]\\n.*?age \\(mae\\): ([\\d.]+)\",\n",
    "        \"val_mae\": r\"\\[val set\\]\\n.*?age \\(mae\\): ([\\d.]+)\",\n",
    "        \"test_mae\": r\"\\[tst set\\]\\n.*?age \\(mae\\): ([\\d.]+)\"\n",
    "    }\n",
    "\n",
    "    # Extract values using regex\n",
    "    results = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, input_text, re.DOTALL)\n",
    "        results[key] = match.group(1) if match else \"-\"\n",
    "\n",
    "    # Format the output\n",
    "    output = (\n",
    "        f\"{results['train_mae']}/{results['train_error']}, \"\n",
    "        f\"-/{results['train_loss']}, \"\n",
    "        f\"{results['val_mae']}/{results['val_error']}, \"\n",
    "        f\"-/{results['val_loss']}, \"\n",
    "        f\"{results['test_mae']}, \"\n",
    "        f\"{results['best_epoch']}/49\"\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "# Input text\n",
    "log_text = \"\"\"\n",
    "2025-01-27 11:33:11,084 [INFO] ----------------------------------------\n",
    "2025-01-27 11:33:29,738 [INFO] [trn phase]\n",
    "2025-01-27 11:33:29,741 [INFO] error: 0.9139 age_error:0.9139\n",
    "2025-01-27 11:33:29,741 [INFO] loss: 0.0467 age_loss:0.0467\n",
    "2025-01-27 11:33:35,769 [INFO] [val phase]\n",
    "2025-01-27 11:33:35,769 [INFO] error: 1.3925 age_error:1.3925\n",
    "2025-01-27 11:33:35,769 [INFO] loss: 0.6457 age_loss:0.6457\n",
    "2025-01-27 11:33:35,769 [INFO] Best Epoch: 9\n",
    "2025-01-27 11:33:36,086 [INFO] Checkpoint saved to facebase/results/Adience_256x256_resnet50_imagenet_noisy_dldl_v2/split2/checkpoint_49.pth\n",
    "2025-01-27 11:33:37,095 [INFO] Training complete in 21m 24s\n",
    "2025-01-27 11:33:37,095 [INFO] Best epoch: 9.000000\n",
    "2025-01-27 11:34:06,231 [INFO] Model evalution:\n",
    "2025-01-27 11:34:06,232 [INFO] [trn set]\n",
    "2025-01-27 11:34:06,232 [INFO] age (mae): 0.8559\n",
    "2025-01-27 11:34:06,232 [INFO] [val set]\n",
    "2025-01-27 11:34:06,232 [INFO] age (mae): 1.3137\n",
    "2025-01-27 11:34:06,232 [INFO] [tst set]\n",
    "2025-01-27 11:34:06,232 [INFO] age (mae): 0.7033\n",
    "\"\"\"\n",
    "\n",
    "# Parse and format the log\n",
    "formatted_output = parse_log_and_format(log_text)\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8638±0.0138/0.9129±0.0153, -/0.0511±0.0046, 1.2313±0.0682/1.2784±0.0839, -/0.6133±0.0397, 0.6611±0.0766, 14.6667±8.7305/49\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_and_calculate(input_text):\n",
    "    # Split input text into rows and then into individual numbers\n",
    "    rows = input_text.strip().split(\"\\n\")\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        # Split by tab, then further split by '/' and remove '-'\n",
    "        parsed_row = []\n",
    "        for item in row.split(\"\\t\"):\n",
    "            parts = item.split(\"/\")\n",
    "            for part in parts:\n",
    "                if part != \"-\":\n",
    "                    parsed_row.append(float(part))\n",
    "        data.append(parsed_row)\n",
    "    \n",
    "    # Convert to numpy array for easier calculations\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Calculate mean and variance for each column\n",
    "    means = np.mean(data, axis=0)\n",
    "    variances = np.sqrt(np.var(data, axis=0))\n",
    "    # Format the output with 4-digit precision\n",
    "    output = (\n",
    "        f\"{means[0]:.4f}±{variances[0]:.4f}/{means[1]:.4f}±{variances[1]:.4f}, \"\n",
    "        f\"-/{means[2]:.4f}±{variances[2]:.4f}, \"\n",
    "        f\"{means[3]:.4f}±{variances[3]:.4f}/{means[4]:.4f}±{variances[4]:.4f}, \"\n",
    "        f\"-/{means[5]:.4f}±{variances[5]:.4f}, \"\n",
    "        f\"{means[6]:.4f}±{variances[6]:.4f}, \"\n",
    "        f\"{means[7]:.4f}±{variances[7]:.4f}/{int(means[8])}\"\n",
    "    )\n",
    "    return output\n",
    "\n",
    "# Input text\n",
    "input_text = \"\"\"\n",
    "0.8832/0.8937\t-/0.0574\t1.2336/1.2493\t-/0.6369\t0.7263\t27/49\n",
    "0.8523/0.9311\t-/0.0491\t1.1467/1.1933\t-/0.5574\t0.5536\t8/49\n",
    "0.8559/0.9139\t-/0.0467\t1.3137/1.3925\t-/0.6457\t0.7033\t9/49\n",
    "\"\"\"\n",
    "\n",
    "# Calculate and print the result\n",
    "result = parse_and_calculate(input_text)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
